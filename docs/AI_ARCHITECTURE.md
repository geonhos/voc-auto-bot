# VOC Auto Bot - AI / Agent 기술 아키텍처

## 1. VOC 입력 시 AI 처리 플로우

### 전체 아키텍처 다이어그램

```
[사용자 VOC 입력]
       │
       ▼
┌─────────────────────────────────────────────────────────────┐
│  Frontend (Next.js)                                         │
│                                                             │
│  ① 제목+내용 입력 (5자/10자 이상)                            │
│       │                                                     │
│       ▼ 1초 디바운스                                         │
│  ② POST /vocs/suggest-category ──────────────────┐          │
│       │                                          │          │
│       ▼                                          │          │
│  ③ AI 카테고리 자동 추천 (카드 하이라이트)            │          │
│     + 우선순위 자동 설정                             │          │
│       │                                          │          │
│       ▼                                          │          │
│  ④ [VOC 등록] 클릭 → POST /vocs                   │          │
└───────┼──────────────────────────────────────────┼──────────┘
        │                                          │
        ▼                                          ▼
┌─────────────────────────────────────────────────────────────┐
│  Backend (Spring Boot / Hexagonal Architecture)             │
│                                                             │
│  ⑤ CreateVocService                                         │
│     ├─ VOC 저장 (PostgreSQL)                                 │
│     ├─ VocAnalysis 레코드 생성 (PENDING)                      │
│     └─ @Async("analysisExecutor") 비동기 분석 트리거           │
│                                                             │
│  ⑥ SuggestCategoryService  ◄─── ② 카테고리 추천 요청          │
│     ├─ 활성 카테고리 목록 조회                                  │
│     ├─ Few-shot 프롬프트 생성                                  │
│     ├─ Ollama LLM 호출 (exaone3.5:7.8b)                      │
│     └─ 최대 3개 카테고리 + confidence + reason 반환             │
│                                                             │
│  ⑦ AsyncVocAnalysisService (비동기 스레드풀)                   │
│     ├─ 상태: PENDING → IN_PROGRESS                            │
│     ├─ VocLogAnalysisService.analyzeLogsForVoc() 호출          │
│     │    ├─ Option A: Python AI Service 호출                   │
│     │    └─ Option B: Fallback (Backend LLM 직접 호출)          │
│     ├─ 분석 결과 저장 (COMPLETED)                               │
│     └─ Slack 알림 전송 (분석 결과 포함)                          │
└───────┼─────────────────────────────────────────────────────┘
        │ POST /api/v1/analyze
        ▼
┌─────────────────────────────────────────────────────────────┐
│  AI Service (FastAPI / Python)                              │
│                                                             │
│  ⑧ Fallback Chain 분석                                      │
│     ├─ 1순위: RAG 분석 (벡터 유사도 검색 + LLM)                │
│     ├─ 2순위: Rule-Based 분석 (키워드 패턴 매칭)               │
│     └─ 3순위: Direct LLM 분석 (컨텍스트 없이)                  │
│                                                             │
│  ⑨ 감성 분석 (Sentiment Analysis)                             │
│     └─ positive / negative / neutral + 감정 강도              │
│                                                             │
│  ⑩ 결과 반환                                                 │
│     ├─ 요약, 키워드, 추정 원인, 권장 조치                       │
│     ├─ 신뢰도 점수 + 분석 방법                                 │
│     └─ 관련 로그 목록 (유사도 점수 포함)                        │
└─────────────────────────────────────────────────────────────┘
```

---

### 단계별 상세 설명

#### ① ~ ③ 프론트엔드: 실시간 AI 카테고리 추천

사용자가 제목과 내용을 입력하는 동안, 프론트엔드는 **1초 디바운스** 후 백엔드에 카테고리 추천을 요청합니다.

```
입력 시작 → 1초 대기 → POST /vocs/suggest-category
                         ↓
                    LLM이 카테고리 분류
                         ↓
            [카드 자동 하이라이트 + 중분류 자동 선택]
            [우선순위 자동 설정 (카테고리 기반)]
```

- **동작 조건**: 제목 5자 이상, 내용 10자 이상
- **캐싱**: TanStack Query (staleTime 5분, gcTime 10분)
- **반환값**: 최대 3개 카테고리 추천 (categoryName, confidence, reason)

#### ④ ~ ⑤ VOC 등록 및 비동기 분석 트리거

VOC가 등록되면 즉시 응답을 반환하고, **백그라운드 스레드풀**에서 AI 분석을 수행합니다.

```
VOC 저장 (동기)
    ├─ DB INSERT (PostgreSQL)
    ├─ VocAnalysis 레코드 생성 (status: PENDING)
    └─ @Async("analysisExecutor") 비동기 분석 시작
         └─ 스레드풀: core=5, max=10, queue=100
```

- 사용자는 VOC 등록 직후 성공 응답을 받음 (비차단)
- AI 분석은 별도 스레드에서 진행 → 완료 시 상태를 COMPLETED로 변경

#### ⑥ LLM 카테고리 추천 (Few-shot Prompting)

```
┌─────────────────────────────────────────┐
│ 프롬프트 구조 (SuggestCategoryService)     │
│                                         │
│ [시스템 역할]                              │
│  "한국어 고객 피드백 분류 전문가"            │
│                                         │
│ [Few-shot 예시 5개]                       │
│  로그인 오류 → 시스템 오류                  │
│  카드 결제 오류 → 결제 오류                 │
│  다크 모드 요청 → 기능 개선                 │
│  비밀번호 재설정 → 계정 관련                │
│  페이지 느림 → 속도/성능                    │
│                                         │
│ [사용자 입력]                              │
│  <user_input>으로 감싸서 인젝션 방지         │
│                                         │
│ [카테고리 목록]                             │
│  DB에서 활성 카테고리 동적 로딩              │
│                                         │
│ [출력 형식]                                │
│  JSON: suggestions[{categoryName,        │
│         confidence, reason}]             │
└─────────────────────────────────────────┘
```

#### ⑧ Fallback Chain 분석 (AI Service)

AI Service는 3단계 Fallback Chain으로 분석 안정성을 보장합니다.

```
┌──────────────────────────────────────────────────┐
│                                                  │
│  1순위: RAG 분석                                   │
│  ┌────────────────────────────────────────────┐  │
│  │ VOC 텍스트 → bge-m3 임베딩 (1024차원)        │  │
│  │      ↓                                     │  │
│  │ pgvector 코사인 유사도 검색 (상위 5개)         │  │
│  │      ↓                                     │  │
│  │ 유사도 ≥ 0.45 인 로그만 필터링                │  │
│  │      ↓                                     │  │
│  │ 관련 로그를 컨텍스트로 LLM에 전달              │  │
│  │      ↓                                     │  │
│  │ 요약 + 키워드 + 원인 + 권장조치 생성           │  │
│  └────────────────────────────────────────────┘  │
│         │ 유사 로그 0건                           │
│         ▼                                        │
│  2순위: Rule-Based 분석                            │
│  ┌────────────────────────────────────────────┐  │
│  │ 키워드 패턴 매칭 (오류, 실패, 느림, 결제 등)   │  │
│  │ 카테고리 자동 감지                            │  │
│  │ 규칙 기반 원인 추정                           │  │
│  └────────────────────────────────────────────┘  │
│         │ 패턴 매칭 실패                          │
│         ▼                                        │
│  3순위: Direct LLM 분석                            │
│  ┌────────────────────────────────────────────┐  │
│  │ 컨텍스트 없이 LLM만으로 분석                   │  │
│  │ 보수적 신뢰도 점수 부여                       │  │
│  └────────────────────────────────────────────┘  │
│                                                  │
└──────────────────────────────────────────────────┘
```

#### 신뢰도(Confidence) 계산 알고리즘

```
최종 점수 = (가중합) × 방법별 보정계수

가중합 = 벡터매칭(35%) + 유사도(25%) + 응답완성도(25%) + 카테고리매칭(15%)

방법별 보정계수:
  RAG:        ×1.0  (가장 높은 신뢰도)
  Rule-Based: ×0.7  (중간 신뢰도)
  Direct LLM: ×0.5  (가장 낮은 신뢰도)

신뢰도 등급:
  HIGH:   ≥ 0.7
  MEDIUM: 0.4 ~ 0.7
  LOW:    < 0.4
```

#### ⑨ 감성 분석 (Sentiment Analysis)

VOC 텍스트의 감정 상태를 분류합니다.

```
입력: VOC 텍스트
  ↓
LLM (temperature=0.1, 결정적 출력)
  ↓
출력:
  ├─ sentiment: positive / negative / neutral
  ├─ confidence: 0.0 ~ 1.0
  └─ emotions:
       ├─ anger: 0.0 ~ 1.0       (분노)
       ├─ frustration: 0.0 ~ 1.0 (좌절)
       ├─ satisfaction: 0.0 ~ 1.0 (만족)
       └─ urgency: 0.0 ~ 1.0     (긴급도)
```

---

## 2. 사용 모델 및 선정 이유

### 모델 구성 요약

| 역할 | 모델 | 크기 | 구동 환경 |
|------|------|------|----------|
| LLM (텍스트 생성) | **EXAONE 3.5** | 7.8B | Ollama (로컬) |
| 임베딩 (벡터 변환) | **BGE-M3** | 567M | Ollama (로컬) |
| 벡터 DB | **PostgreSQL + pgvector** | - | Docker |

---

### LLM: EXAONE 3.5 (7.8B)

> LG AI Research에서 개발한 한국어 특화 대규모 언어 모델

#### 선정 이유

| 기준 | EXAONE 3.5 | 대안 (Llama 3 8B) | 대안 (GPT-4o) |
|------|-----------|-------------------|---------------|
| **한국어 성능** | 네이티브 지원 (한국어 데이터로 사전학습) | 한국어 약함, 영어 중심 | 우수하나 API 비용 발생 |
| **비용** | 무료 (로컬 실행) | 무료 (로컬 실행) | 토큰당 과금 |
| **데이터 보안** | 로컬 실행, 외부 전송 없음 | 로컬 실행 | 외부 API 전송 필요 |
| **응답 속도** | ~2-5초 (Apple Silicon) | ~2-5초 | ~1-3초 (네트워크 의존) |
| **커스터마이징** | 프롬프트 자유 설정 | 프롬프트 자유 설정 | 프롬프트 자유 설정 |

**핵심 선정 이유:**

1. **한국어 네이티브 지원**: 고객 VOC는 100% 한국어이며, EXAONE 3.5는 한국어 데이터로 사전학습되어 자연스러운 한국어 이해와 생성이 가능합니다. Llama 3와 같은 영어 중심 모델은 한국어 분류 정확도가 현저히 낮습니다.

2. **온프레미스 실행 (데이터 보안)**: VOC에는 고객 개인정보(이메일, 이름)와 민감한 불만 사항이 포함됩니다. GPT-4o 같은 외부 API를 사용하면 고객 데이터가 외부로 전송되어 개인정보보호법(PIPA) 및 GDPR 규정 위반 위험이 있습니다. EXAONE은 Ollama를 통해 로컬에서 완전히 실행되므로 데이터가 외부로 나가지 않습니다.

3. **비용 효율**: 외부 LLM API는 VOC 1건당 분석 + 카테고리 추천 + 감성 분석으로 최소 3회 API 호출이 필요합니다. 일일 수백 건의 VOC 처리 시 월 수십만 원의 비용이 발생하지만, EXAONE은 초기 GPU 투자 외 추가 비용이 없습니다.

4. **7.8B 파라미터 크기**: 단일 GPU(Apple Silicon M-시리즈)에서 구동 가능한 최적 크기입니다. 70B 이상 모델은 성능이 좋지만 구동에 고사양 서버가 필요하고, 3B 이하 모델은 한국어 분류 정확도가 부족합니다.

#### 프롬프트 엔지니어링 기법

```
사용 기법:
├─ Few-shot Learning: 5개 실제 VOC 예시로 분류 패턴 학습
├─ System/User Role 분리: 역할 명시로 응답 품질 향상
├─ JSON 강제 출력: "JSON 형식으로만 응답하세요" 명시
├─ Prompt Injection 방지: <user_input> 태그로 사용자 입력 격리
└─ Temperature 조절: 분석=0.3 (약간의 창의성), 감성=0.1 (결정적)
```

---

### 임베딩: BGE-M3

> BAAI(Beijing Academy of AI)에서 개발한 다국어 임베딩 모델

#### 선정 이유

| 기준 | BGE-M3 | 대안 (text-embedding-3-small) | 대안 (multilingual-e5) |
|------|--------|-------------------------------|----------------------|
| **다국어 지원** | 100+ 언어, 한국어 포함 | 우수하나 API 필요 | 한국어 지원 |
| **벡터 차원** | 1024 | 1536 | 768 |
| **비용** | 무료 (로컬) | 토큰당 과금 | 무료 (로컬) |
| **검색 정확도** | Dense + Sparse + Multi-vector | Dense only | Dense only |
| **로컬 실행** | Ollama 지원 | 불가 | HuggingFace |

**핵심 선정 이유:**

1. **Multi-granularity 검색**: BGE-M3는 Dense, Sparse, Multi-vector 세 가지 검색 방식을 동시에 지원합니다. VOC와 로그 매칭에서 의미적 유사도(Dense)와 키워드 매칭(Sparse)을 모두 활용할 수 있습니다.

2. **1024차원 벡터**: 768차원(e5) 대비 더 풍부한 의미 표현이 가능하면서도, 1536차원(OpenAI) 대비 스토리지와 검색 속도가 효율적입니다. VOC-로그 매칭에 적절한 균형점입니다.

3. **한국어 + 영문 로그 동시 처리**: VOC는 한국어이지만 시스템 로그는 영문인 경우가 많습니다. BGE-M3는 다국어 임베딩 공간에서 한국어 VOC와 영문 로그를 동일 벡터 공간으로 매핑하여 언어 간 유사도 검색이 가능합니다.

4. **Ollama 네이티브 지원**: LLM(EXAONE)과 동일한 Ollama 인프라에서 구동되어 별도 임베딩 서버 구축이 불필요합니다.

---

### 벡터 DB: PostgreSQL + pgvector

> PostgreSQL 확장 모듈로 벡터 유사도 검색 지원

#### 선정 이유

| 기준 | pgvector | 대안 (ChromaDB) | 대안 (Pinecone) |
|------|----------|----------------|-----------------|
| **인프라 통합** | 기존 PostgreSQL 재사용 | 별도 서비스 필요 | 클라우드 서비스 |
| **비용** | 무료 (오픈소스) | 무료 | 종량제 과금 |
| **트랜잭션** | ACID 지원 | 미지원 | 미지원 |
| **인덱스** | HNSW, IVFFlat | HNSW | 자동 관리 |
| **SQL 통합** | 네이티브 SQL | Python API only | REST API |
| **운영 복잡도** | 낮음 (기존 DB 확장) | 중간 (별도 프로세스) | 낮음 (관리형) |

**핵심 선정 이유:**

1. **인프라 단순화**: 이미 VOC 데이터 저장에 PostgreSQL을 사용하고 있으므로, pgvector 확장만 추가하면 별도 벡터 DB 없이 동일 데이터베이스에서 벡터 검색이 가능합니다. 서비스 수가 줄어 운영 복잡도가 감소합니다.

2. **ACID 트랜잭션**: VOC 저장과 임베딩 저장을 하나의 트랜잭션으로 처리할 수 있어 데이터 정합성이 보장됩니다. ChromaDB나 Pinecone은 별도 서비스이므로 트랜잭션 보장이 어렵습니다.

3. **HNSW 인덱스**: Hierarchical Navigable Small World 인덱스를 지원하여 대규모 벡터 검색에서도 밀리초 단위의 응답 속도를 제공합니다.

4. **ChromaDB에서 마이그레이션**: 초기에는 ChromaDB를 사용했으나, 별도 프로세스 관리 부담과 유사도 스코어 체계 차이(`[0,1]` vs pgvector의 `[0,2]` 거리)로 인해 pgvector로 통합했습니다.

---

### Ollama (모델 서빙 인프라)

> 로컬 환경에서 LLM과 임베딩 모델을 실행하는 오픈소스 프레임워크

```
Ollama Server (localhost:11434)
  ├─ exaone3.5:7.8b  (LLM - 텍스트 생성)
  └─ bge-m3          (임베딩 - 벡터 변환)
```

**선정 이유:**
- **Apple Silicon 최적화**: M-시리즈 GPU를 활용한 네이티브 가속 (Docker 대비 2-3배 빠름)
- **모델 관리 간소화**: `ollama pull` 한 줄로 모델 다운로드 및 서빙
- **REST API 표준**: `/api/generate`, `/api/embeddings` 엔드포인트로 LangChain과 즉시 연동
- **GPU 메모리 관리**: 모델 자동 로드/언로드로 메모리 효율 최적화

---

## 부록: 기술 스택 전체 구성

```
┌─────────────────────────────────────────────────────┐
│                    Frontend                         │
│  Next.js 14 · React · TypeScript · TanStack Query   │
│  TailwindCSS · React Hook Form · Zod               │
└──────────────────────┬──────────────────────────────┘
                       │ REST API
┌──────────────────────▼──────────────────────────────┐
│                    Backend                          │
│  Spring Boot 3 · Java 17 · Hexagonal Architecture   │
│  Spring Security (JWT) · WebFlux (LLM 호출)         │
│  Spring Async (분석 스레드풀)                         │
└──────────┬───────────────────────────┬──────────────┘
           │ HTTP                      │ JDBC
┌──────────▼──────────┐    ┌───────────▼──────────────┐
│    AI Service       │    │     PostgreSQL            │
│  FastAPI · Python   │    │  pgvector (1024d)         │
│  LangChain          │    │  VOC / Category / User    │
│  Ollama Client      │    │  Embeddings / Metrics     │
└──────────┬──────────┘    └──────────────────────────┘
           │ REST API
┌──────────▼──────────┐
│    Ollama Server    │
│  exaone3.5:7.8b     │
│  bge-m3             │
│  (Apple Silicon GPU)│
└─────────────────────┘
```
